# 2025.12.13 Development Log (LangChain + FastAPI Chat Companion)

## Desktop App Packaging Plan (Electron + Vite)

### Overview
Package the existing Vite frontend into a desktop application (similar to Ollama client) using Electron.

### Installation & Setup
1. Add dev dependencies to `frontend/`:
    - `electron`
    - `electron-builder`

2. Update `package.json` scripts:
```json
{
  "electron:dev": "cross-env NODE_ENV=development electron .",
  "electron:build": "vite build && electron-builder"
}
```

### Electron Main Process
Create `frontend/electron/main.js`:
- Load `dist/index.html` in production
- Load `http://localhost:5173` in development with DevTools
- Disable sandbox and configure `preload.js` if needed for system APIs

### Electron Builder Configuration
Configure `frontend/electron-builder.yml` or `package.json`:
```
appId: <your-app-id>
productName: <your-app-name>
files:
  - dist/**/
  - electron/**/
```

**Target outputs:**
- Windows: nsis
- macOS: dmg/zip
- Linux: AppImage/deb

### Build & Run Workflow
```bash
npm install          # Install all dependencies
npm run build        # Generate dist/
npm run electron:build  # Generate installer
```

### Development Workflow
```bash
npm run dev          # Frontend dev server on :5173
npm run electron:dev # Electron points to dev server
```

### Important Notes
- Backend API must remain accessible (local or LAN)
- Ensure `VITE_API_BASE_URL` consistency in `.env`
- To bundle backend separately, consider PyInstaller or FastAPI startup scripts

推荐走“后端调本地 SD 服务 + 前端调新接口”的思路。两种常见方式：

已有本地 Web 服务：如 Automatic1111 WebUI（默认 http://127.0.0.1:7860/sdapi/v1/txt2img）、InvokeAI/ComfyUI API。
直接在后端用 diffusers + 本地 checkpoint（无现成服务时）。
下面给出基于 A1111 WebUI API 的最小改动方案（不破坏现有聊天流程）：

在 .env 增加 SD 服务地址
STABLE_DIFFUSION_BASE_URL=http://host.docker.internal:7860    # 宿主跑 A1111
STABLE_DIFFUSION_MODEL=your_model_name_or_empty                # 可选，留空用当前模型
后端新增客户端和路由（示意）
新建 backend/app/services/vision/sd_client.py，封装 /sdapi/v1/txt2img 调用。
新建路由 POST /api/v1/image（body: { "prompt": "...", "negative_prompt": "", "steps": 20, "width":512, "height":512 }），返回 base64 图片字符串或直接返回 image/png。
依赖注入读取 STABLE_DIFFUSION_*，在 Docker 里用 host.docker.internal 访问宿主。
前端对接
在 src/api/ 增加 generateImage(prompt)，调用 /api/v1/image，拿到 base64 后显示 <img src="data:image/png;base64,...">。
UI 里加一个“画图”区域或按钮（提示：图形生成可能需要几秒，显示 loading）。
如果没有 A1111，改用 diffusers（会更重）
在 backend 安装 diffusers, transformers, torch CPU/GPU 版本并加模型下载逻辑（耗时/占用大），优先用已有 WebUI/InvokeAI 服务。
部署注意
确保宿主 WebUI 允许外部请求（或在 Docker 网络互通下可访问）。
端口映射：A1111 默认 7860，保持开启。
如需切换成其他 SD 服务，只改 env 和客户端即可。
如果你希望我直接在仓库添加 /api/v1/image 路由和 SD WebUI 客户端，请告诉我，我可以按上述方案落代码。
