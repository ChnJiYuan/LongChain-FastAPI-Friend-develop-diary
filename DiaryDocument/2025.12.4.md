# 2025.12.4 Development Log (LangChain + FastAPI Chat Companion)
## Project Setup & Development Roadmap

### 1. Frontend Initialization

```bash
npm create vite@latest my-app -- --template react-ts
# or
npx create-vite my-app --template react-ts
```

**Rolldown Vite prompt:** Choose based on your needs:
- **Yes** (Rolldown): Faster builds, experimental, potential compatibility issues
- **No** (Traditional Rollup): Stable, mature ecosystem

### 2. Current Project Status

**Backend:** FastAPI + LangChain framework ready; Ollama (local LLM) functional with `llama3.1:8b`

**Frontend:** Vite React-TS initialized; builds successfully but lacks business UI and API integration

**Gaps:** No startup scripts or formal documentation

### 3. Development Phases

**Phase 1 - Foundation:**
- Backend: Add `/healthz` health check, centralize model config in `backend/config.py`
- Frontend: Set `VITE_API_BASE=http://localhost:8000` in `.env`, create API client

**Phase 2 - Core Features:**
- Implement `/chat` endpoint (streaming/single-response)
- Integrate 1-2 example tools (mock weather, document retrieval)
- Build chat UI (message list, input, send button)

**Phase 3 - Polish:**
- Session management (create/switch conversations)
- Model/parameter selection panel
- Error handling and logging
- Health check on frontend startup

### 4. Getting Started

```bash
cd frontend
npm install
npm run dev
```

Open `http://localhost:5173/` to verify setup.

### 5. Next Steps

1. Implement backend `/healthz` and `/chat` endpoints
2. Add frontend API client and basic chat interface
3. Update README with startup commands and Ollama setup instructions



项目现状

后端：FastAPI + LangChain 框架已在仓库；本地 LLM 方案（Ollama）跑通，EverydayStep/12.2/CreateAnAgent.py 可用 llama3.1:8b。
前端：已初始化 Vite React-TS，能成功 npm run build；仍是基础模板，无业务 UI/API 调用。
日志/日记：DiaryDocument 持续记录；未见正式使用指南/启动脚本。
建议的项目流程（按阶段推进）

环境与基础运行

后端：完善 backend/config.py，集中管理模型名/endpoint，本地默认 Ollama；加 /healthz 检查 LLM 服务。
前端：在 frontend/.env 配置 VITE_API_BASE=http://localhost (line 8000)，在 src 增加简单 API 客户端（fetch/axios）。
核心功能对齐

聊天 API：确保 FastAPI 提供 /chat（流式或一次性），支持选择模型；返回格式稳定。
工具/RAG：挑 1-2 个示例工具（天气 mock、文档检索），在 chains 层封装，前端展示工具结果。
前端 UI 搭建

设计基础界面：对话列表 + 输入框 + 发送按钮；显示消息角色/时间；加载态/错误提示。
会话管理：简单的会话列表（基于后端内存/JSON），支持切换/新建会话。
配置面板：可选模型（本地/云）和生成参数（温度、max tokens）。
体验与稳定性

日志与错误：后端记录请求耗时与错误；前端对网络错误/LLM未启动给出提示。
健康检查：前端启动时调用 /healthz，未通过则提示启动 Ollama/后端。
文档与脚本

README：补充快速启动（后端/前端命令）、Ollama 安装与 ollama pull llama3.1:8b、环境变量说明。
脚本：npm run dev（前端），uvicorn backend.main:app --reload 或 make dev；可加 npm run lint、npm run test 占位。
测试与提交

后端：为 /chat 写最小集成测试（mock LLM）；工具调用返回格式测试。
前端：至少手动验收清单（发送消息、切换会话、错误提示）；有余力加简单组件测试。
小步提交：前端 API/界面一次提交，后端 API/健康检查一次提交，文档/脚本一次提交。
下一步立即可做

后端：实现 /healthz，梳理 /chat 返回格式；配置化模型名。
前端：添加 API 客户端和基础聊天 UI，读取 VITE_API_BASE；接上 /chat。
文档：更新根 README/前端 README，写启动步骤和 Ollama 模型拉取说明