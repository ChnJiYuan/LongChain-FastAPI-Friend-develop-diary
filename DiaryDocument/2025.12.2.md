# 2025.12.5 开发日志（LangChain + FastAPI 聊天伙伴）

## 今日目标
- 梳理核心 API（文本聊天、记忆、图像理解/生成）接口约定，确定最小可跑的 FastAPI 骨架。
- 规划 LangChain 链路：对话链、RAG 管线、工具调用链的抽象与数据流。
- 评估 GPU 资源接入方式（本地 LLM + SD 模型），明确配置入口。

## 工作记录
- 初始化 FastAPI 路由草稿：`chat`, `memory`, `image`, `generate` 四个子路由，统一前缀和响应格式；确认采用 pydantic 模型封装请求/响应。
- 设计链路分层：`chains/` 目录按职责拆分 conversation、rag、vision、agent、multimodal；定义它们的输入输出签名，便于后续替换模型或服务。
- 配置入口草案：`config.py` 预留 GPU 检测与模型路径配置（指向本机 RTX 5070 Ti、SD WebUI 模型目录与 SDXL Refiner 权重），计划通过环境变量/本地配置文件加载。
- 日志与监控：决定使用结构化日志，计划在 `utils/logging.py` 中封装 loguru/标准 logging，便于后续接入请求链路 ID。
- 数据与存储：RAG 方案初步确定使用 Chroma 向量库；长记忆使用 JSON（`db/user_profile.json`）做原型，后续再切 PostgreSQL。
- 测试策略：准备在 `tests/` 下添加 API smoke 测试与链路单测，用 pytest + httpx。

## 问题 & 解决
- 问题：Docker daemon 当前未启动，短期内无法用容器化跑依赖服务。  
  解决：本地直跑 FastAPI，暂不依赖容器；待需求稳定后再补 Dockerfile/compose。
- 问题：模型权重体积大，首次加载时间不可控。  
  解决：计划在启动时做懒加载，并通过健康检查端点暴露加载状态。

## 明日计划
- 搭建 FastAPI 最小可运行版本（包含路由注册与健康检查）。
- 在 `config.py` 完成 GPU/模型路径检测与配置结构。
- 起草 `chains/conversation.py` 与 `chains/rag.py` 的伪实现，跑通单轮对话与简单检索。
- 添加基础测试骨架（pytest + httpx）。
